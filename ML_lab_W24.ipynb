{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First, we will need to upload the data. On the left hand sidebar, click the \"folder\" icon to open the file view. Click the upload icon at the top of the pane. Select the file \"data.zip\" to upload it. It will take some time to upload; there should be a progress wheel to monitor its status. This file contains a large number of images (about 5000) along with a CSV (comma-separated values) file with information on each file. Once the file is uploaded, run the following cell (\"Ctrl + Enter\") to unzip it."
      ],
      "metadata": {
        "id": "oi---aR8eRvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ -e /data.zip ]; then unzip -o /data.zip; elif [ -e /content/data.zip ]; then unzip -o /content/data.zip; else echo \"Data not found! Did you forget to upload the data?\"; fi"
      ],
      "metadata": {
        "id": "X58PahrRF0gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When doing machine learning, it is always a good idea to look at the data! Start by opening up the directory /content/data in the sidebar, and double click on some of the images to look at them."
      ],
      "metadata": {
        "id": "h1irkEy4-Pcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define some python classes and functions that we will use for training and testing our models. We provide these since the primary aim of this lab is not to learn to code or to use machine learning libraries; instead, we want to focus on high-level understand of machine learning.\n",
        "\n",
        "In this lab, we use a popular machine-learning library called _PyTorch_, which is used with the _Python_ programming language."
      ],
      "metadata": {
        "id": "mocFvLjegZ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision # deep learning library\n",
        "import torch # deep learning library\n",
        "import pandas as pd # for loading CSV files\n",
        "import sklearn.metrics # for assessing performance\n",
        "from PIL import Image # for loading images\n",
        "from tqdm import tqdm # for progress bars\n",
        "\n",
        "\n",
        "# Define a pytorch dataset.\n",
        "class DermatologyDataset(torch.utils.data.DataLoader):\n",
        "    DIAGNOSES = [\n",
        "            'actinic keratosis',\n",
        "            'basal cell carcinoma',\n",
        "            'dermatofibroma',\n",
        "            'melanoma',\n",
        "            'nevus',\n",
        "            'seborrheic keratosis',\n",
        "            'solar lentigo',\n",
        "            'squamous cell carcinoma'\n",
        "            ]\n",
        "    MALIGNANCIES = [\n",
        "            'basal cell carcinoma',\n",
        "            'melanoma',\n",
        "            'squamous cell carcinoma'\n",
        "            ]\n",
        "    def __init__(self, transform):\n",
        "        '''\n",
        "        Args:\n",
        "            transform: (torchvision transform) A series of transforms that\n",
        "                converts from a PIL Image to a torch tensor\n",
        "        '''\n",
        "        self.data = pd.read_csv('/content/data/labels.csv')\n",
        "        self.data = self.data.query('diagnosis in @self.DIAGNOSES')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Returns:\n",
        "            img: An image, typically represented as a pytorch tensor, though\n",
        "                this is determined by the transform supplied when initializing\n",
        "                the dataset.\n",
        "            label: (int) A binary indicator that is 1 if the image represents a\n",
        "                malignancy, and 0 otherwise.\n",
        "        '''\n",
        "        isic_id = self.data.iloc[idx].isic_id\n",
        "        img = Image.open(f'/content/data/{isic_id}.jpg')\n",
        "        img = self.transform(img)\n",
        "        label = 1 if self.data.iloc[idx].diagnosis in self.MALIGNANCIES else 0\n",
        "        return img, label\n",
        "\n",
        "def get_mobilenet():\n",
        "    '''\n",
        "    Returns:\n",
        "        model: (torch.nn.Module) A pytorch neural network, of the MobileNetV3\n",
        "           architecture. The model is pretrained on ImageNet, and has its final\n",
        "           classification layer modified for a binary prediction task.\n",
        "        transform: (torchvision transforms) The torchvision transforms to be\n",
        "           used with the model (these transform from a \"PIL image\" to a properly\n",
        "           scaled pytorch tensor).\n",
        "    '''\n",
        "    weights = torchvision.models.MobileNet_V3_Small_Weights.DEFAULT # get weights pretrained on ImageNet\n",
        "    model = torchvision.models.mobilenet_v3_small(weights=weights)\n",
        "    model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, 1) # modify model for binary classification\n",
        "    transform = weights.transforms()\n",
        "    # freeze most layers (makes the network train faster)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.classifier[-1].parameters():\n",
        "        param.requires_grad = True\n",
        "    return model, transform\n",
        "\n",
        "def train(model, train_dataset, n_epochs=5):\n",
        "    '''\n",
        "    Train a pytorch neural network using the data in train_dataset.\n",
        "\n",
        "    Args:\n",
        "        model: (torch.nn.Module) A pytorch module, i.e., the neural network\n",
        "            model to train.\n",
        "        train_dataset: (torch.utils.data.Dataset) A pytorch dataset containing\n",
        "            the training data.\n",
        "        n_epochs: (int) The number of epochs, i.e., the number of passes to take\n",
        "            through the dataset when training.\n",
        "    Returns:\n",
        "        model: (torch.nn.Module) The trained pytorch neural network.\n",
        "    '''\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True\n",
        "    )\n",
        "    criterion = torch.nn.BCEWithLogitsLoss() # The training objective to minimize\n",
        "    opt = torch.optim.Adam(model.parameters()) # The optimizer\n",
        "    for epoch in range(5):\n",
        "        # train model\n",
        "        for batch in tqdm(train_dataloader, total=len(train_dataloader)):\n",
        "            imgs, labels = batch\n",
        "            predictions = model(imgs)\n",
        "            loss = criterion(predictions, labels.unsqueeze(1).to(torch.float32))\n",
        "            opt.zero_grad() # reset all previously stored gradients to zero\n",
        "            loss.backward() # backpropagate to calculate gradients\n",
        "            opt.step() # use the gradients to update model's parameters\n",
        "    return model\n",
        "\n",
        "def predict(model, test_dataset):\n",
        "    '''\n",
        "    Calculate the model's predictions for the given dataset.\n",
        "\n",
        "    Args:\n",
        "        model: (torch.nn.Module) A pytorch module, i.e., the (trained) neural\n",
        "            network\n",
        "        test_dataset: The dataset to pass through the model to calculate\n",
        "            predictions.\n",
        "    Returns:\n",
        "        predictions: (torch.Tensor) A pytorch tensor of shape (n,), where n is\n",
        "            the number of samples in `test_dataset`. Each element is a floating\n",
        "            point value between 0 and 1, which may be interpreted as the\n",
        "            probability of melanoma.\n",
        "        labels: (torch.Tensor) A pytorch tensor of shape (n,), where n is the\n",
        "            number of samples in `test_dataset`. Each element is either zero or\n",
        "            one, where one indicates a positive label (e.g., malignant).\n",
        "    '''\n",
        "    test_dataloader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=False\n",
        "    )\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # gradient calculations are not needed during testing\n",
        "        for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
        "            imgs, labels = batch\n",
        "            predictions = model(imgs)\n",
        "            all_predictions.append(predictions)\n",
        "            all_labels.append(labels)\n",
        "    predictions_logits = torch.concat(all_predictions)\n",
        "    predictions_probs = 1/(1+torch.exp(-1*predictions_logits)) # squish to [0,1] range\n",
        "    all_labels = torch.concat(all_labels).squeeze()\n",
        "    return predictions_probs.squeeze(), all_labels\n",
        "def classification_report(labels, predictions, threshold):\n",
        "    report = sklearn.metrics.classification_report(labels, predictions>threshold, output_dict=True)\n",
        "    sensitivity = report['1']['recall']\n",
        "    specificity = report['0']['recall'] # specificity for malignancy is the same as recall for \"benign\"\n",
        "    precision = report['1']['precision']\n",
        "    acc = sklearn.metrics.accuracy_score(labels, predictions>threshold)\n",
        "    roc_auc = sklearn.metrics.roc_auc_score(labels, predictions)\n",
        "    print('Sensitivity: ', \"{:.03f}\".format(sensitivity))\n",
        "    print('Specificity: ', \"{:.03f}\".format(specificity))\n",
        "    print('Precision: ', \"{:.03f}\".format(precision))\n",
        "    print('Accuracy: ', \"{:.03f}\".format(acc))\n",
        "    print('ROC-AUC score: ', \"{:.03f}\".format(roc_auc))"
      ],
      "metadata": {
        "id": "MbWmyOb0HEGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, transform = get_mobilenet()\n",
        "train_dataset = DermatologyDataset(transform)\n",
        "# Subsample the training dataset to reserve a portion for testing.\n",
        "train_dataset.data = train_dataset.data.sample(frac=0.9)\n",
        "test_dataset = DermatologyDataset(transform)\n",
        "# This is a simple shorthand to obtain a test dataset containing all of the\n",
        "# images not in the training dataset\n",
        "test_dataset.data = test_dataset.data.query(\"isic_id not in @train_dataset.data.isic_id\")"
      ],
      "metadata": {
        "id": "y1b0C9hDlJ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(model, train_dataset)\n"
      ],
      "metadata": {
        "id": "cmWzVzFal2E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two blocks of code evaluate the machine's performance on the test data."
      ],
      "metadata": {
        "id": "L80wckqEgsfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels = predict(model, test_dataset)\n"
      ],
      "metadata": {
        "id": "glxdGOPXl3NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(labels, predictions, 0.5) # specify threshold here"
      ],
      "metadata": {
        "id": "Tu3SQbGowo80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two blocks of code evaluate the machine's performance on the training data."
      ],
      "metadata": {
        "id": "WHwSf5rWhBQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions, train_labels = predict(model, train_dataset)"
      ],
      "metadata": {
        "id": "AlzryzTx_cWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(train_labels, train_predictions, 0.5)"
      ],
      "metadata": {
        "id": "0GEvzW9I_lrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's look at how generalizable our model is. Instead of splitting the data randomly into \"test\" and \"training\" groups we will seperate our data by hospital site. We will reserve all the images from Memorial Sloan Kettering Cancer Center for testing."
      ],
      "metadata": {
        "id": "IVlN5uJNhLCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2, transform = get_mobilenet()\n",
        "train_dataset_2 = DermatologyDataset(transform)\n",
        "test_dataset_2 = DermatologyDataset(transform)\n",
        "# This time, we want our test data to come only from a single institution\n",
        "test_dataset_2.data = test_dataset_2.data.query(\"attribution == 'Memorial Sloan Kettering Cancer Center'\")\n",
        "\n",
        "# We want the training dataset to contain the remainder of the images (from\n",
        "# institutions other than the Memorial Sloan Kettering Cancer Center).\n",
        "train_dataset.data = train_dataset_2.data.query(\"isic_id not in @test_dataset_2.data.isic_id\")\n",
        "print(\"Length of train dataset: \", len(train_dataset_2))\n",
        "print(\"Length of test dataset: \", len(test_dataset_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LPNwsC9so8n",
        "outputId": "7e168278-4025-4d0d-a48d-d6b0bf774729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train dataset:  4352\n",
            "Length of test dataset:  531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = train(model_2, train_dataset_2)\n"
      ],
      "metadata": {
        "id": "-VKrQcjwuSAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_2, labels_2 = predict(model_2, test_dataset_2)"
      ],
      "metadata": {
        "id": "KDc8isevzuRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(labels_2, predictions_2, 0.5)"
      ],
      "metadata": {
        "id": "W7PeLTuNubSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save you from having to program this yourself, we pre-programmed the code in the following box to allow you to create datasets split on sex, age, and the type of instrument (dermatoscope) used to acquire the image. You should not need to edit this code at all, but you can read the description under each function to see how to use it; see the comments under the functions marked with triple hash-tags (\"###\")."
      ],
      "metadata": {
        "id": "u3E-gTiNLogO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_dataset(dataset):\n",
        "    labels = [1 if diagnosis in dataset.MALIGNANCIES else 0 for diagnosis in dataset.data.diagnosis]\n",
        "    if not 1 in labels:\n",
        "        print(\"Warning! A dataset contains only benign lesions. This will cause \"\n",
        "              \"unexpected behavior when training and testing models. Choose a \"\n",
        "              \"different way to split data in order to avoid this situation.\")\n",
        "        return False\n",
        "    if not 0 in labels:\n",
        "        print(\"Warning! A dataset contains only malignant lesions. This will cause \"\n",
        "              \"unexpected behavior when training and testing models. Choose a \"\n",
        "              \"different way to split data in order to avoid this situation.\")\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def run_precheck(dataset_a, dataset_b):\n",
        "    print(\"Length of first dataset is: \", len(dataset_a))\n",
        "    print(\"Length of second dataset is: \", len(dataset_b))\n",
        "    print(\"Number of malignancies in first dataset is: \",\n",
        "          sum([1 if diagnosis in dataset_a.MALIGNANCIES else 0 for diagnosis in dataset_a.data.diagnosis]))\n",
        "    print(\"Number of malignancies in second dataset is: \",\n",
        "          sum([1 if diagnosis in dataset_b.MALIGNANCIES else 0 for diagnosis in dataset_b.data.diagnosis]))\n",
        "    check_dataset(dataset_a)\n",
        "    check_dataset(dataset_b)\n",
        "    return\n",
        "\n",
        "### FOR SPLITTING DATASETS ON SEX ###\n",
        "def get_dataset_split_sex(transform, dataset_a_sex='female'):\n",
        "    '''\n",
        "    Returns two datasets, where each dataset contains patients of a single sex.\n",
        "\n",
        "    Args:\n",
        "      transform: The transforms to be used in the dataset\n",
        "      dataset_a_sex: (str) Either 'female' or 'male'. The first dataset returned\n",
        "        will contain patients of only this sex, while the second dataset will\n",
        "        contain the remaining patients.\n",
        "    Returns:\n",
        "      dataset_a: A dataset of dermatology images.\n",
        "      dataset_b: Another dataset of dermatology images, disjoint from dataset_a.\n",
        "    '''\n",
        "    if not dataset_a_sex.lower() in ['female', 'male']:\n",
        "        raise ValueError('dataset_a_sex needs to be either \"female\" or \"male\"')\n",
        "    dataset_a_sex = dataset_a_sex.lower()\n",
        "    dataset_a = DermatologyDataset(transform)\n",
        "    dataset_b = DermatologyDataset(transform)\n",
        "    dataset_a.data = dataset_a.data.query('sex == @dataset_a_sex')\n",
        "    dataset_b.data = dataset_b.data.query('isic_id not in @dataset_a.data.isic_id')\n",
        "    check_dataset(dataset_a)\n",
        "    check_dataset(dataset_b)\n",
        "    return dataset_a, dataset_b\n",
        "\n",
        "### FOR SPLITTING DATASETS ON AGE ###\n",
        "def get_dataset_split_age(transform, dataset_a_upper_bound=30):\n",
        "    '''\n",
        "    Returns two datasets, where each dataset contains patients of differing\n",
        "    ages. The first dataset will contain younger patients, and the second dataset\n",
        "    contains older patients.\n",
        "\n",
        "    Args:\n",
        "      transform: The transforms to be used in the dataset\n",
        "      dataset_a_upper_bound: (int) An integer between 5 and 75, specifying the\n",
        "        maximum age (inclusive) of patients in dataset_a.\n",
        "    Returns:\n",
        "      dataset_a: A dataset of dermatology images.\n",
        "      dataset_b: Another dataset of dermatology images, disjoint from dataset_a.\n",
        "    '''\n",
        "    if not isinstance(dataset_a_upper_bound, int):\n",
        "        raise ValueError('dataset_a_upper_bound needs to be an integer.')\n",
        "    if dataset_a_upper_bound < 5 or dataset_a_upper_bound > 75:\n",
        "        raise ValueError('dataset_a_upper_bound needs to be between 5 and 75')\n",
        "    dataset_a = DermatologyDataset(transform)\n",
        "    dataset_b = DermatologyDataset(transform)\n",
        "    dataset_a.data = dataset_a.data.query('age_approx <= @dataset_a_upper_bound')\n",
        "    dataset_b.data = dataset_b.data.query('isic_id not in @dataset_a.data.isic_id')\n",
        "    run_precheck(dataset_a, dataset_b)\n",
        "    return dataset_a, dataset_b\n",
        "\n",
        "### FOR SPLITTING DATASETS ON IMAGE ACQUISITION METHOD ###\n",
        "def get_dataset_split_dermoscopic_type(\n",
        "        transform,\n",
        "        dataset_a_type='contact polarized',\n",
        "        dataset_b_type='contact non-polarized'):\n",
        "    '''\n",
        "    Returns two datasets, where each dataset contains images acquired with\n",
        "    different types of dermoscopy. Most dermoscopy is \"contact\" dermoscopy in\n",
        "    which the dermatoscope touches the skin, and contact dermoscopy can use\n",
        "    either polarized or non-polarized light. There is also non-contact\n",
        "    dermoscopy, which always uses polarized light.\n",
        "\n",
        "    Args:\n",
        "      transform: The transforms to be used in the dataset\n",
        "      dataset_a_type: (str) Either 'contact polarized', 'contact non-polarized',\n",
        "        or 'non-contact polarized'. Specifies the type of dermatoscope used to\n",
        "        acquire images in dataset_a.\n",
        "      dataset_b_type: (str) Either 'contact polarized', 'contact non-polarized',\n",
        "        or 'non-contact polarized'. Specifies the type of dermatoscope used to\n",
        "        acquire images in dataset_b. THIS MUST BE DIFFERENT THAN dataset_a_type.\n",
        "    Returns:\n",
        "      dataset_a: A dataset of dermatology images.\n",
        "      dataset_b: Another dataset of dermatology images, disjoint from dataset_a.\n",
        "    '''\n",
        "    dataset_a_type == dataset_a_type.lower()\n",
        "    dataset_b_type == dataset_b_type.lower()\n",
        "    options = ['contact polarized', 'contact non-polarized', 'non-contact polarized']\n",
        "    if not dataset_a_type in options:\n",
        "        raise ValueError(\"dataset_a_type must be one of \" + str(options))\n",
        "    if not dataset_b_type in options:\n",
        "        raise ValueError(\"dataset_b_type must be one of \" + str(options))\n",
        "    if dataset_a_type == dataset_b_type:\n",
        "        raise ValueError(\"dataset_a_type and dataset_b_type must differ.\")\n",
        "    dataset_a = DermatologyDataset(transform)\n",
        "    dataset_b = DermatologyDataset(transform)\n",
        "    dataset_a.data = dataset_a.data.query('dermoscopic_type == @dataset_a_type')\n",
        "    dataset_b.data = dataset_b.data.query('dermoscopic_type == @dataset_b_type')\n",
        "    run_precheck(dataset_a, dataset_b)\n",
        "    return dataset_a, dataset_b"
      ],
      "metadata": {
        "id": "m4X9p3p0Ll5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}